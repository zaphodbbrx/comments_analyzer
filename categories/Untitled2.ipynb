{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.read_excel('manual_labels.xlsx')\n",
    "unlabeled = pd.read_excel('manual_unlabeled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\W',' ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    res = ''\n",
    "    for t in tokens:\n",
    "        res += wnl.lemmatize(t)+' '\n",
    "    return res\n",
    "def get_tokens(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\W',' ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled['tokens'] = labeled.Review.apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_long = labeled[labeled.tokens.apply(len)>6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review</th>\n",
       "      <th>lang</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18260</th>\n",
       "      <td>18260</td>\n",
       "      <td>5</td>\n",
       "      <td>Best ive played since a kid when it first came...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>[Best, ive, played, since, a, kid, when, it, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>13087</td>\n",
       "      <td>1</td>\n",
       "      <td>I can't download The New update</td>\n",
       "      <td>en</td>\n",
       "      <td>5</td>\n",
       "      <td>[I, can, t, download, The, New, update]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42370</th>\n",
       "      <td>42370</td>\n",
       "      <td>5</td>\n",
       "      <td>If this game wasn't made my life would be took...</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>[If, this, game, wasn, t, made, my, life, woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>12018</td>\n",
       "      <td>1</td>\n",
       "      <td>THIS SUCKS IT GAVE MME BACK ONLY MY ARMOR FOR ...</td>\n",
       "      <td>en</td>\n",
       "      <td>3</td>\n",
       "      <td>[THIS, SUCKS, IT, GAVE, MME, BACK, ONLY, MY, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14980</th>\n",
       "      <td>14980</td>\n",
       "      <td>5</td>\n",
       "      <td>I got every thing in the game yay</td>\n",
       "      <td>en</td>\n",
       "      <td>4</td>\n",
       "      <td>[I, got, every, thing, in, the, game, yay]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Rating                                             Review  \\\n",
       "18260       18260       5  Best ive played since a kid when it first came...   \n",
       "13087       13087       1                    I can't download The New update   \n",
       "42370       42370       5  If this game wasn't made my life would be took...   \n",
       "12018       12018       1  THIS SUCKS IT GAVE MME BACK ONLY MY ARMOR FOR ...   \n",
       "14980       14980       5                  I got every thing in the game yay   \n",
       "\n",
       "      lang  label                                             tokens  \n",
       "18260   en      4  [Best, ive, played, since, a, kid, when, it, f...  \n",
       "13087   en      5            [I, can, t, download, The, New, update]  \n",
       "42370   en      4  [If, this, game, wasn, t, made, my, life, woul...  \n",
       "12018   en      3  [THIS, SUCKS, IT, GAVE, MME, BACK, ONLY, MY, A...  \n",
       "14980   en      4         [I, got, every, thing, in, the, game, yay]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    255\n",
       "2    175\n",
       "5     65\n",
       "3     28\n",
       "0     18\n",
       "1      8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_long.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoLarsCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       #max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(unlabeled.Review)\n",
    "feats = vect.transform(labeled_long.Review).toarray()\n",
    "labels = labeled_long.label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 3168)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(y_train,y_test,y_train_pred,y_test_pred):\n",
    "    \n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    \n",
    "    class_names_b = ['neg', 'pos']\n",
    "    print('train scores\\n')\n",
    "    print(classification_report(y_train, y_train_pred, target_names = class_names))\n",
    "    print('test scores\\n')\n",
    "    print(classification_report(y_test, y_test_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.00      0.00      0.00        13\n",
      "           Crash       0.00      0.00      0.00         7\n",
      "Balance problems       0.28      0.10      0.15       118\n",
      " Synchronization       0.00      0.00      0.00        19\n",
      "        Positive       0.48      0.43      0.45       180\n",
      "             Bug       0.13      0.49      0.21        47\n",
      "\n",
      "     avg / total       0.33      0.29      0.28       384\n",
      "\n",
      "test scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.00      0.00      0.00         5\n",
      "           Crash       0.00      0.00      0.00         1\n",
      "Balance problems       0.33      0.14      0.20        57\n",
      " Synchronization       0.00      0.00      0.00         9\n",
      "        Positive       0.44      0.45      0.45        75\n",
      "             Bug       0.11      0.33      0.16        18\n",
      "\n",
      "     avg / total       0.33      0.29      0.29       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "m = OneVsRestClassifier(DummyClassifier()).fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.93      1.00      0.96        13\n",
      "           Crash       1.00      1.00      1.00         7\n",
      "Balance problems       0.96      0.88      0.92       118\n",
      " Synchronization       1.00      1.00      1.00        19\n",
      "        Positive       0.93      0.97      0.95       180\n",
      "             Bug       0.91      0.91      0.91        47\n",
      "\n",
      "     avg / total       0.94      0.94      0.94       384\n",
      "\n",
      "test scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.00      0.00      0.00         5\n",
      "           Crash       0.00      0.00      0.00         1\n",
      "Balance problems       0.74      0.60      0.66        57\n",
      " Synchronization       0.67      0.22      0.33         9\n",
      "        Positive       0.70      0.92      0.79        75\n",
      "             Bug       0.64      0.39      0.48        18\n",
      "\n",
      "     avg / total       0.68      0.68      0.66       165\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression(class_weight = 'balanced', C = .5).fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_en = pd.read_excel('validation_en.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(input_text,model = m):\n",
    "    feats = vect.transform([input_text])\n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    class_names_b = ['neg', 'pos']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    #print(class_names[prediction[0]])\n",
    "    return class_names[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            Positive\n",
       "1                 Bug\n",
       "2                 Bug\n",
       "3    Balance problems\n",
       "4               Crash\n",
       "5               Crash\n",
       "6               Crash\n",
       "7                 Bug\n",
       "8               Crash\n",
       "9            Positive\n",
       "Name: Crash, dtype: object"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en.Crash.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
