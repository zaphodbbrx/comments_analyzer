{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "comments = pd.read_csv('../comments_en_cleaned.csv')\n",
    "comments_en = comments[comments.lang == 'en']\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments_en.Review)\n",
    "pw = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled4 = pd.read_excel('../temp data/for_labeling 4.xlsx').loc[:,['Review', 'Label', 'Sublabel']]\n",
    "labeled1 = pd.read_excel('../temp data/for_labeling 1.xlsx').loc[:,['Review', 'Label', 'Sublabel']]\n",
    "labeled2 = pd.read_excel('../temp data/for_labeling 2.xlsx').loc[:,['Review', 'Label', 'Sublabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    49\n",
       "1.0    24\n",
       "2.0    11\n",
       "Name: Sublabel, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled2.Sublabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled1.Sublabel = labeled1.Sublabel.apply(lambda x: str(x).lower())\n",
    "labeled4.Sublabel = labeled4.Sublabel.apply(lambda x: str(x).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan                 4955\n",
       "combat balance        24\n",
       "matchmaking           17\n",
       "gameplay balance      11\n",
       "Name: Sublabel, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled4.Sublabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_nums = {\n",
    "    'Balance':1,\n",
    "    'Graphics':2,\n",
    "    'Bug':3,\n",
    "    'Advertising':4,\n",
    "    'Monetization':5,\n",
    "    'Other':0\n",
    "}\n",
    "subclasses_nums = {\n",
    "    'combat balance': 1,\n",
    "    'gameplay balance':2,\n",
    "    'matchmaking':3\n",
    "}\n",
    "labeled1['sublabel_num'] = labeled1.Sublabel.map(subclasses_nums)\n",
    "labeled4['sublabel_num'] = labeled4.Sublabel.map(subclasses_nums)\n",
    "labeled2['sublabel_num'] = labeled2.Sublabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    49\n",
       "1.0    24\n",
       "2.0    11\n",
       "Name: sublabel_num, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled2.sublabel_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "labeled1['label_num'] = labeled1.Label.map(classes_nums)\n",
    "labeled4['label_num'] = labeled4.Label.map(classes_nums)\n",
    "\n",
    "labeled1['sublabel_num'] = labeled1.Sublabel.map(subclasses_nums)\n",
    "labeled4['sublabel_num'] = labeled4.Sublabel.map(subclasses_nums)\n",
    "\n",
    "labeled2['label_num'] = labeled2.Label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled4[labeled4.label_num==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan                 4955\n",
       "combat balance        24\n",
       "matchmaking           17\n",
       "gameplay balance      11\n",
       "Name: Sublabel, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled4.Sublabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    24\n",
       "3.0    17\n",
       "2.0    11\n",
       "Name: sublabel_num, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled4.sublabel_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.concat([labeled4, labeled2, labeled1], axis = 0)\n",
    "labeled = labeled.dropna(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    73\n",
       "3.0    69\n",
       "2.0    22\n",
       "Name: sublabel_num, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.sublabel_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled = pd.read_excel('model_labeled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_balance = unlabeled[unlabeled.model_label==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(830, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_balance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import emoji\n",
    "\n",
    "c = enchant.Dict(\"en_UK\")\n",
    "def check_spelling(text):\n",
    "    if not c.check(text):\n",
    "        suggestions = list(set(c.suggest(text)).intersection(set(pw)))\n",
    "        if len(suggestions)>0:\n",
    "            res = suggestions[0]\n",
    "        elif len(c.suggest(text))>0:\n",
    "            res = c.suggest(text)[0]\n",
    "        else:\n",
    "            res = text\n",
    "    else:\n",
    "        res = text\n",
    "    return res\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    #deacc = re.sub(r'\\!',' exclamation_point ', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    processed = []\n",
    "    for (word, tag) in tags:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag!='':\n",
    "            processed.append(wnl.lemmatize(check_spelling(word),wn_tag))\n",
    "        else:\n",
    "            processed.append(wnl.lemmatize(check_spelling(word)))\n",
    "    res = ' '.join(processed)\n",
    "    return res.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.loc[:,'cleaned'] = labeled.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_combat = labeled[labeled.sublabel_num==1]\n",
    "labeled_gameplay = labeled[labeled.sublabel_num==2]\n",
    "labeled_matchmaking = labeled[labeled.sublabel_num==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "def get_top_words(df, filename):\n",
    "    vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                           stop_words = 'english',\n",
    "                           #max_features = 200,\n",
    "                           min_df = 2, max_df = 0.95)\n",
    "    vectors = vect.fit_transform(df.cleaned)\n",
    "    z = zip(vect.get_feature_names(),\n",
    "        np.asarray(vectors.sum(axis=0)*1000/vectors.shape[0]).ravel())\n",
    "    freqs = pd.Series()\n",
    "    for fn,cnt in z:\n",
    "        freqs[fn] = cnt\n",
    "    freqs.sort_values(ascending = False).to_excel(filename+'.xlsx')\n",
    "    return freqs.sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#combat_freqs = get_top_words(labeled_combat, 'combat_topwords')\n",
    "#gameplay_freqs = get_top_words(labeled_gameplay, 'gameplay_topwords')\n",
    "#matchmaking_freqs = get_top_words(labeled_matchmaking, 'matchmaking_topwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "def check4word(w, freqs):\n",
    "    if w in freqs.index:\n",
    "        return freqs.loc[w].tolist()[0]\n",
    "    else:\n",
    "        return 0\n",
    "def get_cat_by_kw(text):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    cleaned = clean_comment(text)\n",
    "    tokens         = tokenizer.tokenize(cleaned)\n",
    "    cat_freqs      = pd.DataFrame(columns = tokens)\n",
    "    combat_freqs    = pd.read_excel('combat_topwords.xlsx')\n",
    "    gameplay_freqs  = pd.read_excel('gameplay_topwords.xlsx')\n",
    "    matchmaking_freqs = pd.read_excel('matchmaking_topwords.xlsx')\n",
    "    classes_nums = {\n",
    "        'Combat Balance':1,\n",
    "        'Gameplay Balance':2,\n",
    "        'Matchmaking':3,\n",
    "        'Other':0\n",
    "    }    \n",
    "    for w in tokens:\n",
    "        #cat_freqs.loc['Other',w] = check4word(w,other_freqs)\n",
    "        cat_freqs.loc['Combat Balance',w] = check4word(w,combat_freqs)\n",
    "        cat_freqs.loc['Gameplay Balance',w] = check4word(w,gameplay_freqs)\n",
    "        cat_freqs.loc['Matchmaking',w] = check4word(w,matchmaking_freqs)\n",
    "    if cat_freqs.apply(sum).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return classes_nums[cat_freqs.apply(sum,axis =1).idxmax()]\n",
    "    return cat_freqs#.apply(sum,axis =1).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_by_kw('Matchmaking is unfair')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "unlabeled_balance['sublabel'] = unlabeled_balance.loc[:,'Review'].apply(get_cat_by_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    382\n",
       "2    216\n",
       "0    133\n",
       "3     99\n",
       "Name: sublabel, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_balance.sublabel.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_combat = unlabeled_balance[unlabeled_balance.sublabel==1]\n",
    "labeled_gameplay = unlabeled_balance[unlabeled_balance.sublabel==2]\n",
    "labeled_matchmaking = unlabeled_balance[unlabeled_balance.sublabel==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combat_freqs = get_top_words(labeled_combat, 'it1/combat_topwords')\n",
    "gameplay_freqs = get_top_words(labeled_gameplay, 'it1/gameplay_topwords')\n",
    "matchmaking_freqs = get_top_words(labeled_matchmaking, 'it1/matchmaking_topwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "def check4word(w, freqs):\n",
    "    if w in freqs.index:\n",
    "        return freqs.loc[w].tolist()[0]\n",
    "    else:\n",
    "        return 0\n",
    "def get_cat_by_kw(text):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    cleaned = clean_comment(text)\n",
    "    tokens         = tokenizer.tokenize(cleaned)\n",
    "    cat_freqs      = pd.DataFrame(columns = tokens)\n",
    "    combat_freqs    = pd.read_excel('it1/combat_topwords.xlsx')\n",
    "    gameplay_freqs  = pd.read_excel('it1/gameplay_topwords.xlsx')\n",
    "    matchmaking_freqs = pd.read_excel('it1/matchmaking_topwords.xlsx')\n",
    "    classes_nums = {\n",
    "        'Combat Balance':1,\n",
    "        'Gameplay Balance':2,\n",
    "        'Matchmaking':3,\n",
    "        'Other':0\n",
    "    }    \n",
    "    for w in tokens:\n",
    "        #cat_freqs.loc['Other',w] = check4word(w,other_freqs)\n",
    "        cat_freqs.loc['Combat Balance',w] = check4word(w,combat_freqs)\n",
    "        cat_freqs.loc['Gameplay Balance',w] = check4word(w,gameplay_freqs)\n",
    "        cat_freqs.loc['Matchmaking',w] = check4word(w,matchmaking_freqs)\n",
    "    if cat_freqs.apply(sum).sum()==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return classes_nums[cat_freqs.apply(sum,axis =1).idxmax()]\n",
    "    return cat_freqs#.apply(sum,axis =1).idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_by_kw(' Can you pls nerfed the primary weapons like mega gun, and anything because some people killing me with mega gun... And we are not rich, we are poor! Other players are stealing their mom\\'s credit but we didn\\'t do that... All the guns are high price?!! What?!! This is not even a rich man game, this is PIXEL GUN!!! And i want just to say.... I haven\\'t a armory button... Can you pls give me I\\'m not even happy when I started to play pg3d... Pls give me... ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_cat_by_kw('Great game! But its just the lucky chest! Please make it so we dont get coins and gems everytime! Put more guns and gadgets or make it so we get 50 gems instead of 3 5 and 10 ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_cat_by_kw(' This is amazing, I can\\'t stop playing. So many different weapons, gadgets, and game modes that is basically Minecraft in a shooting game but better! ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cat_by_kw(' Piss poor matchmaking is what is scaring me away from this game. That is literally the only reason why I would not recommend anyone to play this. The grind to stand a chance against the veterans you will be matched with frequently is not worth it. It gets 2 stars for overall gameplay. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Other       0.27      0.80      0.40         5\n",
      "     Combat       0.10      0.20      0.13         5\n",
      "   Gameplay       0.00      0.00      0.00         5\n",
      "Matchmaking       0.20      0.20      0.20         5\n",
      "\n",
      "avg / total       0.09      0.20      0.12        30\n",
      "\n",
      "model accuracy 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1428: UserWarning: labels size, 6, does not match size of target_names, 4\n",
      "  .format(len(labels), len(target_names))\n",
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score\n",
    "\n",
    "def val_score():\n",
    "    class_names = ['Other',\n",
    "        'Combat',\n",
    "        'Gameplay',\n",
    "        'Matchmaking']   \n",
    "    val_en = pd.read_excel('../temp data/val google play 2.xlsx')\n",
    "    classes_nums = {\n",
    "        'Combat':1,\n",
    "        'Gameplay':2,\n",
    "        'Matchmaking':3,\n",
    "        'Other':0\n",
    "    }    \n",
    "    #val_en['label_num'] = val_en.Label.map(classes_nums)\n",
    "    y_true = val_en.Label\n",
    "    y_pred = val_en.Review.apply(get_cat_by_kw)\n",
    "    val_en['predicted'] = y_pred\n",
    "    val_en.to_excel('predicted.xlsx')\n",
    "    print(classification_report(y_true, y_pred, target_names = class_names))\n",
    "    print('model accuracy %1.4f'%(accuracy_score(y_true, y_pred)))\n",
    "    return y_true,y_pred\n",
    "y_true,y_pred = val_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
