{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.read_excel('manual_labels.xlsx')\n",
    "unlabeled = pd.read_excel('manual_unlabeled.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\W',' ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    res = ''\n",
    "    for t in tokens:\n",
    "        res += wnl.lemmatize(t)+' '\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled['label_b'] = labeled.label.apply(lambda x: 1 if x==4 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled['cleaned'] = labeled.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57204                                    Thismgame is fun \n",
       "18260    Best ive played since a kid when it first came...\n",
       "52241                           I think this app is great \n",
       "13087                     I can t download The New update \n",
       "42370    If this game wasn t made my life would be took...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled['label_b'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pd.concat([labeled[['Review', 'label_b']], unlabeled[['Review','label_b']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoLarsCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,3), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(labeled.Review)\n",
    "feats = vect.transform(labeled.Review).toarray()\n",
    "labels = labeled.label_b.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 500)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(y_train,y_test,y_train_pred,y_test_pred):\n",
    "    \n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    \n",
    "    class_names_b = ['neg', 'pos']\n",
    "    print('train scores\\n')\n",
    "    print(classification_report(y_train, y_train_pred, target_names = class_names_b))\n",
    "    print('test scores\\n')\n",
    "    print(classification_report(y_test, y_test_pred, target_names = class_names_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.37      0.37      0.37       303\n",
      "        pos       0.61      0.61      0.61       497\n",
      "\n",
      "avg / total       0.52      0.52      0.52       800\n",
      "\n",
      "test scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.44      0.44      0.44        73\n",
      "        pos       0.68      0.69      0.68       127\n",
      "\n",
      "avg / total       0.59      0.59      0.59       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = OneVsRestClassifier(DummyClassifier()).fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.95      0.77      0.85       303\n",
      "        pos       0.87      0.98      0.92       497\n",
      "\n",
      "avg / total       0.90      0.90      0.89       800\n",
      "\n",
      "test scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.62      0.73        73\n",
      "        pos       0.81      0.96      0.88       127\n",
      "\n",
      "avg / total       0.84      0.83      0.83       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MultinomialNB().fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.49      0.63       293\n",
      "        pos       0.77      0.96      0.85       507\n",
      "\n",
      "avg / total       0.81      0.79      0.77       800\n",
      "\n",
      "test scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.85      0.42      0.56        83\n",
      "        pos       0.70      0.95      0.80       117\n",
      "\n",
      "avg / total       0.76      0.73      0.70       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = KNeighborsClassifier(n_neighbors = 10).fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_en = pd.read_excel('validation_en.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(input_text,model = m):\n",
    "    feats = vect.transform([input_text])\n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    class_names_b = ['neg', 'pos']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    #print(class_names[prediction[0]])\n",
    "    return class_names_b[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    neg\n",
       "1    pos\n",
       "2    neg\n",
       "3    neg\n",
       "4    neg\n",
       "5    neg\n",
       "6    neg\n",
       "7    neg\n",
       "8    pos\n",
       "9    neg\n",
       "Name: Bug, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en.Bug.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.25, gamma=1000, kernel='knn', max_iter=15, n_jobs=-1,\n",
       "        n_neighbors=10, tol=0.001)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import label_propagation\n",
    "from scipy.sparse import csgraph\n",
    "lp_model = label_propagation.LabelSpreading(kernel = 'knn',gamma = 1000, n_neighbors = 10,alpha = 0.25, max_iter=15, n_jobs = -1)\n",
    "lp_model.fit(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9602\n",
       "0    4198\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lp_model.transduction_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = lp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_p = lp_model.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total['label_p'] = labels_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    9602\n",
       "0    4198\n",
       "Name: label_p, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.label_p.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    neg\n",
       "1    pos\n",
       "2    pos\n",
       "3    pos\n",
       "4    neg\n",
       "5    pos\n",
       "6    neg\n",
       "7    neg\n",
       "8    neg\n",
       "9    pos\n",
       "Name: Balance, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en.Balance.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,2), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       strip_accents = 'unicode',\n",
    "                       min_df = 2, max_df = 0.95).fit(total.Review)\n",
    "feats = vect.transform(total.Review).toarray()\n",
    "labels = total.label_p.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13800, 9994)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.64756346\n",
      "Validation score: 0.706975\n",
      "Iteration 2, loss = 0.44269012\n",
      "Validation score: 0.825181\n",
      "Iteration 3, loss = 0.25299290\n",
      "Validation score: 0.835598\n",
      "Iteration 4, loss = 0.14227583\n",
      "Validation score: 0.836504\n",
      "Iteration 5, loss = 0.08732756\n",
      "Validation score: 0.831069\n",
      "Iteration 6, loss = 0.05936568\n",
      "Validation score: 0.830616\n",
      "Iteration 7, loss = 0.04568356\n",
      "Validation score: 0.826540\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n",
      "train scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.90      0.93      0.91      3365\n",
      "        pos       0.97      0.96      0.96      7675\n",
      "\n",
      "avg / total       0.95      0.95      0.95     11040\n",
      "\n",
      "test scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.69      0.72      0.70       833\n",
      "        pos       0.88      0.86      0.87      1927\n",
      "\n",
      "avg / total       0.82      0.82      0.82      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MLPClassifier(activation = 'relu',\n",
    "                  hidden_layer_sizes = [50,50,25],\n",
    "                  early_stopping = True, validation_fraction = 0.2,\n",
    "                  verbose = 1).fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.80      0.56      0.66      3365\n",
      "        pos       0.83      0.94      0.88      7675\n",
      "\n",
      "avg / total       0.82      0.82      0.81     11040\n",
      "\n",
      "test scores\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.61      0.47      0.53       833\n",
      "        pos       0.79      0.87      0.83      1927\n",
      "\n",
      "avg / total       0.73      0.75      0.74      2760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = MultinomialNB().fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(input_text,model = m):\n",
    "    feats = vect.transform([input_text])\n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    class_names_b = ['neg', 'pos', 'uncertain']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    \"\"\"\n",
    "    if prediction_prob[0][1]>0.9:\n",
    "        prediction = 1\n",
    "    elif prediction_prob[0][0]>0.6:\n",
    "        prediction = 0\n",
    "    else:\n",
    "        prediction = 2\n",
    "    \"\"\"\n",
    "    #print(class_names[prediction[0]])\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "5    0\n",
       "6    0\n",
       "7    0\n",
       "8    1\n",
       "9    0\n",
       "Name: Bug, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en.Bug.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled['label_p'] = unlabeled.Review.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unlabeled_neg = unlabeled[unlabeled['label_p']<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "unlabeled_neg.loc[:,'label'] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_neg = labeled[labeled.label!=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = pd.concat([labeled_neg[['Review', 'label']], unlabeled_neg[['Review','label']]], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    3875\n",
       " 2     203\n",
       " 5      74\n",
       " 0      60\n",
       " 3      31\n",
       " 1       8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,3), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(total.Review)\n",
    "feats = vect.transform(total.Review).toarray()\n",
    "labels = total.label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py:293: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.label_distributions_ /= normalizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LabelSpreading(alpha=0.1, gamma=1000, kernel='knn', max_iter=15, n_jobs=-1,\n",
       "        n_neighbors=15, tol=0.001)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.semi_supervised import label_propagation\n",
    "from scipy.sparse import csgraph\n",
    "lp_model = label_propagation.LabelSpreading(kernel = 'knn',gamma = 1000, n_neighbors = 15,alpha = 0.1, max_iter=15, n_jobs = -1)\n",
    "lp_model.fit(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2067\n",
       "2    1480\n",
       "5     489\n",
       "3     136\n",
       "1      79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lp_model.transduction_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels_p = lp_model.transduction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total['label_p'] = labels_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['label_p'] = total.label_p.apply(lambda x: 4 if x == 5 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2067\n",
       "2    1480\n",
       "4     489\n",
       "3     136\n",
       "1      79\n",
       "Name: label_p, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.label_p.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total['cleaned'] = total.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,5), analyzer = 'char_wb',\n",
    "                       stop_words = 'english',\n",
    "                       min_df = 2, max_df = 0.95).fit(total.Review)\n",
    "feats = vect.transform(total.Review).toarray()\n",
    "labels = total.label_p.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4251, 24439)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, LassoLarsCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(y_train,y_test,y_train_pred,y_test_pred):\n",
    "    \n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        #'Positive',\n",
    "        'Bug']\n",
    "    \n",
    "    class_names_b = ['neg', 'pos']\n",
    "    print('train scores\\n')\n",
    "    print(classification_report(y_train, y_train_pred, target_names = class_names))\n",
    "    print('test scores\\n')\n",
    "    print(classification_report(y_test, y_test_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.87      0.79      0.83      1657\n",
      "           Crash       0.62      1.00      0.76        69\n",
      "Balance problems       0.80      0.79      0.79      1184\n",
      " Synchronization       0.68      0.90      0.77       116\n",
      "             Bug       0.65      0.81      0.72       374\n",
      "\n",
      "     avg / total       0.81      0.80      0.80      3400\n",
      "\n",
      "test scores\n",
      "\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "         unknown       0.74      0.71      0.73       410\n",
      "           Crash       0.14      0.30      0.19        10\n",
      "Balance problems       0.71      0.68      0.69       296\n",
      " Synchronization       0.12      0.20      0.15        20\n",
      "             Bug       0.54      0.56      0.55       115\n",
      "\n",
      "     avg / total       0.68      0.66      0.67       851\n",
      "\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression(C = 0.01,\n",
    "                 class_weight = 'balanced').fit(X_train, y_train)\n",
    "y_train_pred = m.predict(X_train)\n",
    "y_test_pred = m.predict(X_test)\n",
    "eval_model(y_train,y_test,y_train_pred,y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_classifier(input_text,model = m):\n",
    "    feats = vect.transform([input_text])\n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        #'Positive',\n",
    "        'Bug']\n",
    "    class_names_b = ['neg', 'pos', 'uncertain']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    \"\"\"\n",
    "    if prediction_prob[0][1]>0.9:\n",
    "        prediction = 1\n",
    "    elif prediction_prob[0][0]>0.6:\n",
    "        prediction = 0\n",
    "    else:\n",
    "        prediction = 2\n",
    "    \"\"\"\n",
    "    #print(class_names[prediction[0]])\n",
    "    return class_names[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Balance problems\n",
       "1    Balance problems\n",
       "2               Crash\n",
       "3                 Bug\n",
       "4                 Bug\n",
       "5                 Bug\n",
       "6    Balance problems\n",
       "7    Balance problems\n",
       "8             unknown\n",
       "9             unknown\n",
       "Name: Bug, dtype: object"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_en.Bug.apply(eval_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total.to_csv('label_prop_neg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2067\n",
       "2    1480\n",
       "4     489\n",
       "3     136\n",
       "1      79\n",
       "Name: label_p, dtype: int64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.label_p.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
