{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "comments = pd.read_csv('comments_en_cleaned.csv')\n",
    "comments_en = comments[comments.lang == 'en']\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments_en.Review)\n",
    "pw = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "c = enchant.Dict(\"en_UK\")\n",
    "def check_spelling(text):\n",
    "    if not c.check(text):\n",
    "        suggestions = list(set(c.suggest(text)).intersection(set(pw)))\n",
    "        if len(suggestions)>0:\n",
    "            res = suggestions[0]\n",
    "        else:\n",
    "            res = text\n",
    "    else:\n",
    "        res = text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import emoji\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\!',' exclamation_point ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    processed = []\n",
    "    for (word, tag) in tags:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag!='':\n",
    "            processed.append(wnl.lemmatize(word,wn_tag))\n",
    "        else:\n",
    "            processed.append(wnl.lemmatize(check_spelling(word)))\n",
    "    res = ' '.join(processed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_nums = {\n",
    "    'Balance':1,\n",
    "    'Graphics':2,\n",
    "    'Bug':3,\n",
    "    'Advertising':4,\n",
    "    'Monetization':5,\n",
    "    'Other':0\n",
    "}\n",
    "labeled4 = pd.read_excel('temp data/for_labeling 4.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled1 = pd.read_excel('temp data/for_labeling 1.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled2 = pd.read_excel('temp data/for_labeling 2.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled2 = labeled2[(labeled2.Label!='?')&(labeled2.Label!='-')]\n",
    "labeled1['label_num'] = labeled1.Label.map(classes_nums)\n",
    "labeled4['label_num'] = labeled4.Label.map(classes_nums)\n",
    "labeled2['label_num'] = labeled2.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.concat([labeled4, labeled2, labeled1], axis = 0)\n",
    "labeled = labeled.dropna(axis = 0)\n",
    "labeled.label_num = labeled.label_num.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut_major_class(df, frac = 0.5):\n",
    "    major_class = df.Label.value_counts().index[0]\n",
    "    dfmc = df[df.Label==major_class].sample(frac = frac)\n",
    "    df_rest = df[df.Label!=major_class]\n",
    "    return pd.concat([dfmc, df_rest],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#labeled = cut_major_class(labeled, frac = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4265, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.loc[:,'cleaned'] = labeled.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'use'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_spelling('osume')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3452\n",
       "3     355\n",
       "5     221\n",
       "1     165\n",
       "2      63\n",
       "4       9\n",
       "Name: label_num, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.label_num.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.to_excel('new_labeled_4000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier,RidgeClassifierCV,LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       #max_features = 10000,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments_en.cleaned)\n",
    "vocab = vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(y_train,y_test,y_train_pred,y_test_pred):\n",
    "    \n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']\n",
    "    \n",
    "    class_names_b = ['neg', 'pos']\n",
    "    print('train scores\\n')\n",
    "    print(classification_report(y_train, y_train_pred, target_names = class_names))\n",
    "    print('test scores\\n')\n",
    "    print(classification_report(y_test, y_test_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "vect = CountVectorizer()\n",
    "model = RidgeClassifierCV()\n",
    "scaler = MaxAbsScaler()\n",
    "lin_model = Pipeline([('vectorizer', vect),\n",
    "                      #('features', FeatureUnion([\n",
    "                      #  ('ngram_tf_idf', Pipeline([\n",
    "                      #    ('counts', CountVectorizer()),\n",
    "                      #    ('tf_idf', TfidfTransformer())]))\n",
    "                      #])),\n",
    "                        #('scaler', scaler),\n",
    "                      ('classifier', model)])\n",
    "lin_model.set_params(vectorizer__ngram_range = (1,3),vectorizer__analyzer = 'word', vectorizer__stop_words = 'english',\n",
    "                     vectorizer__max_features = 700,\n",
    "                     vectorizer__min_df = 2, vectorizer__max_df = 0.95,\n",
    "                     vectorizer__vocabulary = vocab,\n",
    "                     \n",
    "                     classifier__class_weight = 'balanced')#,classifier__alpha = 0.75)\n",
    "feats = labeled.cleaned\n",
    "labels = labeled.label_num\n",
    "#X_train, X_test, y_train, y_test = train_test_split(feats.tolist(), labels.tolist(), test_size=0.2)\n",
    "lin_model = lin_model.fit(feats, labels)\n",
    "#y_train_pred = lin_model.predict(X_train)\n",
    "#y_test_pred = lin_model.predict(X_test)\n",
    "#eval_model(y_train,y_test,y_train_pred,y_test_pred)\n",
    "print('cross_val_score: %1.4f'% (np.mean(cross_val_score(lin_model, labeled.cleaned,labeled.label_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score: 0.8321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "vect = CountVectorizer()\n",
    "model = LogisticRegressionCV()\n",
    "scaler = MaxAbsScaler()\n",
    "lin_model = Pipeline([#('vectorizer', vect),\n",
    "                      ('features', FeatureUnion([\n",
    "                        ('ngram_tf_idf', Pipeline([\n",
    "                          ('counts', CountVectorizer()),\n",
    "                          ('tf_idf', TfidfTransformer())]))\n",
    "                      ])),\n",
    "                        ('scaler', scaler),\n",
    "                      ('classifier', model)])\n",
    "lin_model.set_params(#vectorizer__ngram_range = (1,3),vectorizer__analyzer = 'word', vectorizer__stop_words = 'english',\n",
    "                     #vectorizer__max_features = 1000,\n",
    "                     #vectorizer__min_df = 2, vectorizer__max_df = 0.95,\n",
    "                     #vectorizer__vocabulary = vocab,\n",
    "                     \n",
    "                     classifier__class_weight = 'balanced',classifier__Cs = np.logspace(start = 0.01, stop = 50, num = 25))\n",
    "feats = labeled.cleaned\n",
    "labels = labeled.label_num\n",
    "#X_train, X_test, y_train, y_test = train_test_split(feats.tolist(), labels.tolist(), test_size=0.2)\n",
    "lin_model = lin_model.fit(feats, labels)\n",
    "#y_train_pred = lin_model.predict(X_train)\n",
    "#y_test_pred = lin_model.predict(X_test)\n",
    "#eval_model(y_train,y_test,y_train_pred,y_test_pred)\n",
    "print('cross_val_score: %1.4f'% (np.mean(cross_val_score(lin_model, labeled.cleaned,labeled.label_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 123.85589065,  123.85589065,    1.02329299,    1.02329299,\n",
       "          1.02329299,    1.02329299])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_model.named_steps['classifier'].C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.56      1.00      0.71         5\n",
      "     Balance       1.00      0.80      0.89         5\n",
      "    Graphics       1.00      1.00      1.00         5\n",
      "         Bug       0.80      0.80      0.80         5\n",
      " Advertising       1.00      0.20      0.33         5\n",
      "Monetization       0.83      1.00      0.91         5\n",
      "\n",
      " avg / total       0.86      0.80      0.77        30\n",
      "\n",
      "model accuracy 0.8000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score\n",
    "def eval_classifier(input_text,model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    feats = vect.transform([cleaned_text])\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    #print(class_names[prediction[0]])\n",
    "    return prediction[0]\n",
    "def eval_pipeline(input_text, model = lin_model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']\n",
    "    prediction = model.predict([cleaned_text])\n",
    "    #print(class_names[prediction[0]])\n",
    "    return prediction[0]\n",
    "def val_score(model):\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']   \n",
    "    val_en = pd.read_excel('temp data/val google play 2.xlsx')\n",
    "    classes_nums = {\n",
    "        'Balance':1,\n",
    "        'Graphics':2,\n",
    "        'Bug':3,\n",
    "        'Advertising':4,\n",
    "        'Monetization':5,\n",
    "        'Other':0\n",
    "    }    \n",
    "    #val_en['label_num'] = val_en.Label.map(classes_nums)\n",
    "    y_true = val_en.Label\n",
    "    y_pred = val_en.Review.apply(eval_pipeline)\n",
    "    val_en['predicted'] = y_pred\n",
    "    val_en.to_excel('predicted.xlsx')\n",
    "    print(classification_report(y_true, y_pred, target_names = class_names))\n",
    "    print('model accuracy %1.4f'%(accuracy_score(y_true, y_pred)))\n",
    "    return y_true,y_pred\n",
    "y_true,y_pred = val_score(lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter class_weight for estimator LassoLarsCV(copy_X=True, cv=None, eps=2.2204460492503131e-16,\n      fit_intercept=True, max_iter=500, max_n_alphas=1000, n_jobs=1,\n      normalize=True, positive=False, precompute='auto', verbose=False). Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-7ac0fd3eeccd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                      \u001b[0mvectorizer__min_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer__max_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                      classifier__class_weight = 'balanced')\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m param_grid = {\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \"\"\"\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py\u001b[0m in \u001b[0;36m_set_params\u001b[0;34m(self, attr, **params)\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_replace_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;31m# 3. Step parameters and other initilisation arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_BaseComposition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_params\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnested_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m             \u001b[0mvalid_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0msub_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m                                  \u001b[0;34m'Check the list of available parameters '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                                  \u001b[0;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m                                  (key, self))\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdelim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter class_weight for estimator LassoLarsCV(copy_X=True, cv=None, eps=2.2204460492503131e-16,\n      fit_intercept=True, max_iter=500, max_n_alphas=1000, n_jobs=1,\n      normalize=True, positive=False, precompute='auto', verbose=False). Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LassoLarsCV\n",
    "vect = CountVectorizer()\n",
    "model = LassoLarsCV()\n",
    "lin_model = Pipeline([('vectorizer', vect), ('classifier', model)])\n",
    "lin_model.set_params(vectorizer__analyzer = 'word', vectorizer__stop_words = 'english',\n",
    "                     vectorizer__min_df = 2, vectorizer__max_df = 0.95,\n",
    "                     \n",
    "                     classifier__class_weight = 'balanced')\n",
    "\n",
    "param_grid = {\n",
    "        'vectorizer__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "        'vectorizer__max_features': [200,250,300,350,400],        \n",
    "        'classifier__alpha':np.logspace(start = 0.001, stop = 0.5, num = 10)#[0.1, 0.2, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]\n",
    "    }\n",
    "\n",
    "gs = GridSearchCV(lin_model, cv=3, n_jobs=-1, param_grid=param_grid, verbose = 1)\n",
    "feats = labeled.cleaned\n",
    "labels = labeled.label_num\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "gs = gs.fit(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-e0bbbc8d643f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gs' is not defined"
     ]
    }
   ],
   "source": [
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('It\\'s good but it crashes way to much and it\\'s so pay to win I could make a whole day ranting about how unfair it is and maybe your game might become better if you listen what other people want like no armor sever and more this game could be better if you listened to what other people want like less overpowered weapons and less overpriced things')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('prototype was supposed to be powerful btw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('graphics are strong in this one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('the game crashes like every 5 minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('Way to many ads. Thats so annoying')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('weapons prices are just crazy! pg3d r u nuts?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_pipeline('The game is so unfair when i level up some higher than me pops up i die all the time you earn money and you cant fix this ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
