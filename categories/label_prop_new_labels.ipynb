{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "comments = pd.read_csv('comments_en_cleaned.csv')\n",
    "comments_en = comments[comments.lang == 'en']\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 500,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments_en.Review)\n",
    "pw = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"pw.txt\", \"w\") as text_file:\n",
    "    for w in pw:\n",
    "        print(w, file=text_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "c = enchant.Dict(\"en_UK\")\n",
    "def check_spelling(text):\n",
    "    if not c.check(text):\n",
    "        suggestions = list(set(c.suggest(text)).intersection(set(pw)))\n",
    "        if len(suggestions)>0:\n",
    "            res = suggestions[0]\n",
    "        elif len(c.suggest(text))>0:\n",
    "            res = c.suggest(text)[0]\n",
    "        else:\n",
    "            res = text\n",
    "    else:\n",
    "        res = text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,TreebankWordTokenizer\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import emoji\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    #deacc = re.sub(r'\\!',' exclamation_point ', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    processed = []\n",
    "    for (word, tag) in tags:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag!='':\n",
    "            processed.append(wnl.lemmatize(check_spelling(word),wn_tag))\n",
    "        else:\n",
    "            processed.append(wnl.lemmatize(check_spelling(word)))\n",
    "    res = ' '.join(processed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes_nums = {\n",
    "    'Balance':1,\n",
    "    'Graphics':2,\n",
    "    'Bug':3,\n",
    "    'Advertising':4,\n",
    "    'Monetization':5,\n",
    "    'Other':0\n",
    "}\n",
    "labeled4 = pd.read_excel('temp data/for_labeling 4.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled1 = pd.read_excel('temp data/for_labeling 1.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled2 = pd.read_excel('temp data/for_labeling 2.xlsx').loc[:,['Review', 'Label']]\n",
    "labeled2 = labeled2[(labeled2.Label!='?')&(labeled2.Label!='-')]\n",
    "labeled1['label_num'] = labeled1.Label.map(classes_nums)\n",
    "labeled4['label_num'] = labeled4.Label.map(classes_nums)\n",
    "labeled2['label_num'] = labeled2.Label\n",
    "labeled = pd.concat([labeled4, labeled2, labeled1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled['label_num'] = labeled.label_num.fillna(-1)\n",
    "labeled.label_num = labeled.label_num.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.loc[:,'cleaned'] = labeled.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "class DenseTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val_score: 0.2324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.semi_supervised import label_propagation\n",
    "from scipy.sparse import csgraph\n",
    "from sklearn.model_selection import cross_val_score\n",
    "vect = CountVectorizer()\n",
    "#model = RidgeClassifierCV()\n",
    "lp_model = label_propagation.LabelSpreading(kernel = 'rbf',gamma = 0.25, n_neighbors = 10,alpha = 0.5, max_iter=15, n_jobs = -1)\n",
    "scaler = MaxAbsScaler()\n",
    "lin_model = Pipeline([('vectorizer', vect),\n",
    "                      ('dense_transformer', DenseTransformer()),\n",
    "                      ('classifier', lp_model)])\n",
    "lin_model.set_params(vectorizer__ngram_range = (1,3),vectorizer__analyzer = 'word', vectorizer__stop_words = 'english',\n",
    "                     vectorizer__max_features = 800,\n",
    "                     vectorizer__min_df = 2, vectorizer__max_df = 0.95)\n",
    "feats = labeled.cleaned\n",
    "labels = labeled.label_num\n",
    "lin_model = lin_model.fit(feats, labels)\n",
    "print('cross_val_score: %1.4f'% (np.mean(cross_val_score(lin_model, labeled.cleaned,labeled.label_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13630\n",
       "3      564\n",
       "5      375\n",
       "1      166\n",
       "2      104\n",
       "4       14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lin_model.named_steps['classifier'].transduction_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer(ngram_range = (1,3),\n",
    "                       analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 1000,\n",
    "                       min_df = 2, max_df = 0.9).fit(total.Review)\n",
    "feats = vect.transform(total.Review).toarray()\n",
    "labels = total.label.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13800, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'i like the gun and the armor and skin gadget and everything # AW SOME'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-93c634c62b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_propagation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLabelSpreading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'rbf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/semi_supervised/label_propagation.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \"\"\"\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    431\u001b[0m                                       force_all_finite)\n\u001b[1;32m    432\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'i like the gun and the armor and skin gadget and everything # AW SOME'"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import label_propagation\n",
    "from scipy.sparse import csgraph\n",
    "lp_model = label_propagation.LabelSpreading(kernel = 'rbf',gamma = 0.1, n_neighbors = 10,alpha = 0.2, max_iter=15)\n",
    "lp_model.fit(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp_model.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    9804\n",
       "0    2567\n",
       "2     912\n",
       "5     388\n",
       "3      88\n",
       "1      41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(lp_model.transduction_).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Other       0.17      1.00      0.29         5\n",
      "     Balance       0.00      0.00      0.00         5\n",
      "    Graphics       0.00      0.00      0.00         5\n",
      "         Bug       0.00      0.00      0.00         5\n",
      " Advertising       0.00      0.00      0.00         5\n",
      "Monetization       1.00      0.20      0.33         5\n",
      "\n",
      " avg / total       0.20      0.20      0.10        30\n",
      "\n",
      "model accuracy 0.2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lsm/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score, classification_report\n",
    "\n",
    "def eval_classifier(input_text,model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    feats = vect.transform([cleaned_text])\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']\n",
    "    prediction = model.predict(feats.toarray())\n",
    "    #print(class_names[prediction[0]])\n",
    "    return prediction[0]\n",
    "def eval_pipeline(input_text, model = lin_model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']\n",
    "    prediction = model.predict([cleaned_text])\n",
    "    #print(class_names[prediction[0]])\n",
    "    return prediction[0]\n",
    "def val_score(model):\n",
    "    class_names = ['Other',\n",
    "        'Balance',\n",
    "        'Graphics',\n",
    "        'Bug',\n",
    "        'Advertising',\n",
    "        'Monetization']   \n",
    "    val_en = pd.read_excel('temp data/val google play 2.xlsx')\n",
    "    classes_nums = {\n",
    "        'Balance':1,\n",
    "        'Graphics':2,\n",
    "        'Bug':3,\n",
    "        'Advertising':4,\n",
    "        'Monetization':5,\n",
    "        'Other':0\n",
    "    }    \n",
    "    #val_en['label_num'] = val_en.Label.map(classes_nums)\n",
    "    y_true = val_en.Label\n",
    "    y_pred = val_en.Review.apply(eval_pipeline)\n",
    "    val_en['predicted'] = y_pred\n",
    "    val_en.to_excel('predicted.xlsx')\n",
    "    print(classification_report(y_true, y_pred, target_names = class_names))\n",
    "    print('model accuracy %1.4f'%(accuracy_score(y_true, y_pred)))\n",
    "    return y_true,y_pred\n",
    "y_true,y_pred = val_score(lin_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
