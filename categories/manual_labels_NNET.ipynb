{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "comments = pd.read_csv('../data/comments_lang.csv')\n",
    "comments_en = comments[comments.lang == 'en']\n",
    "vect = CountVectorizer(ngram_range = (1,1), analyzer = 'word',\n",
    "                       stop_words = 'english',\n",
    "                       max_features = 10000,\n",
    "                       min_df = 2, max_df = 0.95).fit(comments_en.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pw = list(vect.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant\n",
    "c = enchant.Dict(\"en_UK\")\n",
    "def check_spelling(text):\n",
    "    if not c.check(text):\n",
    "        suggestions = list(set(c.suggest(text)).intersection(set(pw)))\n",
    "        if len(suggestions)>0:\n",
    "            res = suggestions[0]\n",
    "        else:\n",
    "            res = text\n",
    "    else:\n",
    "        res = text\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'god'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_spelling('gud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled1 = pd.read_excel('manual_labels.xlsx')\n",
    "labeled2 = pd.read_excel('manual_labels2.xlsx')\n",
    "labeled3 = pd.read_excel('manual_labels3.xlsx')\n",
    "labeled4 = pd.read_excel('manual_labels4.xlsx')\n",
    "labeled5 = pd.read_excel('manual_labels5.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    621\n",
       "2    172\n",
       "5     89\n",
       "0     82\n",
       "3     25\n",
       "1     11\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled5.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    624\n",
       "2    203\n",
       "5     74\n",
       "0     60\n",
       "3     31\n",
       "1      8\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled1.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\W',' ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    res = ''\n",
    "    for t in tokens:\n",
    "        res += wnl.lemmatize(t)+' '\n",
    "    return res\n",
    "def get_tokens(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\W',' ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from emoji.unicode_codes import UNICODE_EMOJI\n",
    "import emoji\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def clean_comment(text):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    deacc = re.sub(r'\\!',' exclamation_point ', text)\n",
    "    tokens = word_tokenize(deacc)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    processed = []\n",
    "    for (word, tag) in tags:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag!='':\n",
    "            processed.append(wnl.lemmatize(word,wn_tag))\n",
    "        else:\n",
    "            processed.append(wnl.lemmatize(check_spelling(word)))\n",
    "    res = ' '.join(processed)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled = pd.concat([labeled1, labeled2, labeled3, labeled4, labeled5],axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled.loc[:,'cleaned'] = labeled.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled['tokens'] = labeled.Review.apply(get_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labeled_long = labeled[labeled.tokens.apply(len)>6]\n",
    "labeled_neg = labeled[labeled.label!=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#comments_en['cleaned'] = comments_en.Review.apply(clean_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#comments_en.to_csv('comments_en_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments_en = pd.read_csv('comments_en_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.models import load_model\n",
    "import re\n",
    "import keras.backend as K\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Tokenizer()\n",
    "\n",
    "#rds = corpus[rd.tokens.apply(len)>5]\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(comments_en.cleaned.tolist())\n",
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_docs = t.texts_to_sequences(labeled.cleaned)\n",
    "max_length = labeled.tokens.apply(len).max()\n",
    "feats = encoded_docs\n",
    "labels = to_categorical(labeled.label)\n",
    "X_train, X_test, y_train, y_test = train_test_split(feats, labels, test_size=0.2)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(vocab_size, 150, \n",
    "                    input_length=max_length,\n",
    "                   embeddings_regularizer = regularizers.l2(1e-3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=100, kernel_size=25, padding='same', activation='sigmoid'))\n",
    "model.add(Conv1D(filters=25, kernel_size=25, padding='same', activation='sigmoid'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "#model.add(Flatten())\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(10, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = compute_class_weight('balanced'\n",
    "                                               ,[0,1,2,3,4,5]\n",
    "                                               ,labeled.label.apply(int).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 3.0585 - categorical_accuracy: 0.1989 \n",
      "Epoch 00001: val_loss improved from inf to 2.42423, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 71s 18ms/step - loss: 2.9940 - categorical_accuracy: 0.2255 - val_loss: 2.4242 - val_categorical_accuracy: 0.5910\n",
      "Epoch 2/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 2.2414 - categorical_accuracy: 0.4857 \n",
      "Epoch 00002: val_loss improved from 2.42423 to 1.87397, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 71s 18ms/step - loss: 2.2060 - categorical_accuracy: 0.4877 - val_loss: 1.8740 - val_categorical_accuracy: 0.5910\n",
      "Epoch 3/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.7983 - categorical_accuracy: 0.5383 \n",
      "Epoch 00003: val_loss improved from 1.87397 to 1.58254, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 70s 18ms/step - loss: 1.7785 - categorical_accuracy: 0.5463 - val_loss: 1.5825 - val_categorical_accuracy: 0.5910\n",
      "Epoch 4/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.5495 - categorical_accuracy: 0.5794 \n",
      "Epoch 00004: val_loss improved from 1.58254 to 1.41804, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 74s 19ms/step - loss: 1.5372 - categorical_accuracy: 0.5800 - val_loss: 1.4180 - val_categorical_accuracy: 0.5910\n",
      "Epoch 5/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.4185 - categorical_accuracy: 0.5846 \n",
      "Epoch 00005: val_loss improved from 1.41804 to 1.32462, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 70s 17ms/step - loss: 1.4219 - categorical_accuracy: 0.5845 - val_loss: 1.3246 - val_categorical_accuracy: 0.5910\n",
      "Epoch 6/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.3488 - categorical_accuracy: 0.5866 \n",
      "Epoch 00006: val_loss improved from 1.32462 to 1.28438, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 70s 18ms/step - loss: 1.3411 - categorical_accuracy: 0.5913 - val_loss: 1.2844 - val_categorical_accuracy: 0.5910\n",
      "Epoch 7/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.3108 - categorical_accuracy: 0.5951 \n",
      "Epoch 00007: val_loss improved from 1.28438 to 1.26350, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 76s 19ms/step - loss: 1.3091 - categorical_accuracy: 0.5960 - val_loss: 1.2635 - val_categorical_accuracy: 0.5910\n",
      "Epoch 8/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.3026 - categorical_accuracy: 0.5960 \n",
      "Epoch 00008: val_loss improved from 1.26350 to 1.25426, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 70s 17ms/step - loss: 1.2983 - categorical_accuracy: 0.5955 - val_loss: 1.2543 - val_categorical_accuracy: 0.5910\n",
      "Epoch 9/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2932 - categorical_accuracy: 0.5966 \n",
      "Epoch 00009: val_loss improved from 1.25426 to 1.24974, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2956 - categorical_accuracy: 0.5970 - val_loss: 1.2497 - val_categorical_accuracy: 0.5910\n",
      "Epoch 10/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2994 - categorical_accuracy: 0.5946 \n",
      "Epoch 00010: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2941 - categorical_accuracy: 0.5965 - val_loss: 1.2515 - val_categorical_accuracy: 0.5910\n",
      "Epoch 11/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2859 - categorical_accuracy: 0.5931 \n",
      "Epoch 00011: val_loss improved from 1.24974 to 1.24597, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 1.2814 - categorical_accuracy: 0.5970 - val_loss: 1.2460 - val_categorical_accuracy: 0.5910\n",
      "Epoch 12/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2950 - categorical_accuracy: 0.6000 \n",
      "Epoch 00012: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2937 - categorical_accuracy: 0.6015 - val_loss: 1.2502 - val_categorical_accuracy: 0.5910\n",
      "Epoch 13/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2876 - categorical_accuracy: 0.5989 \n",
      "Epoch 00013: val_loss improved from 1.24597 to 1.24381, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2888 - categorical_accuracy: 0.5977 - val_loss: 1.2438 - val_categorical_accuracy: 0.5910\n",
      "Epoch 14/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2772 - categorical_accuracy: 0.5991 \n",
      "Epoch 00014: val_loss improved from 1.24381 to 1.23863, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2790 - categorical_accuracy: 0.5965 - val_loss: 1.2386 - val_categorical_accuracy: 0.5910\n",
      "Epoch 15/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2592 - categorical_accuracy: 0.5963 \n",
      "Epoch 00015: val_loss improved from 1.23863 to 1.23783, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 68s 17ms/step - loss: 1.2606 - categorical_accuracy: 0.5985 - val_loss: 1.2378 - val_categorical_accuracy: 0.5910\n",
      "Epoch 16/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.2685 - categorical_accuracy: 0.5960 \n",
      "Epoch 00016: val_loss improved from 1.23783 to 1.23431, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 73s 18ms/step - loss: 1.2620 - categorical_accuracy: 0.5995 - val_loss: 1.2343 - val_categorical_accuracy: 0.5910\n",
      "Epoch 17/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.2647 - categorical_accuracy: 0.5966 \n",
      "Epoch 00017: val_loss improved from 1.23431 to 1.23422, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 1.2597 - categorical_accuracy: 0.5983 - val_loss: 1.2342 - val_categorical_accuracy: 0.5910\n",
      "Epoch 18/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2566 - categorical_accuracy: 0.5991 \n",
      "Epoch 00018: val_loss improved from 1.23422 to 1.23107, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2574 - categorical_accuracy: 0.6005 - val_loss: 1.2311 - val_categorical_accuracy: 0.5910\n",
      "Epoch 19/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2482 - categorical_accuracy: 0.6040 \n",
      "Epoch 00019: val_loss improved from 1.23107 to 1.22888, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2541 - categorical_accuracy: 0.6015 - val_loss: 1.2289 - val_categorical_accuracy: 0.5910\n",
      "Epoch 20/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2432 - categorical_accuracy: 0.6040 \n",
      "Epoch 00020: val_loss improved from 1.22888 to 1.22707, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2503 - categorical_accuracy: 0.6002 - val_loss: 1.2271 - val_categorical_accuracy: 0.5910\n",
      "Epoch 21/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2589 - categorical_accuracy: 0.5943 \n",
      "Epoch 00021: val_loss improved from 1.22707 to 1.22543, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2568 - categorical_accuracy: 0.5957 - val_loss: 1.2254 - val_categorical_accuracy: 0.5910\n",
      "Epoch 22/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2556 - categorical_accuracy: 0.5989 \n",
      "Epoch 00022: val_loss improved from 1.22543 to 1.22211, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2560 - categorical_accuracy: 0.5975 - val_loss: 1.2221 - val_categorical_accuracy: 0.5910\n",
      "Epoch 23/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2352 - categorical_accuracy: 0.6009 \n",
      "Epoch 00023: val_loss improved from 1.22211 to 1.21925, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2394 - categorical_accuracy: 0.5995 - val_loss: 1.2193 - val_categorical_accuracy: 0.5910\n",
      "Epoch 24/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2501 - categorical_accuracy: 0.5894 \n",
      "Epoch 00024: val_loss improved from 1.21925 to 1.21678, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2374 - categorical_accuracy: 0.5972 - val_loss: 1.2168 - val_categorical_accuracy: 0.5910\n",
      "Epoch 25/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2401 - categorical_accuracy: 0.5977 \n",
      "Epoch 00025: val_loss improved from 1.21678 to 1.21289, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2397 - categorical_accuracy: 0.5983 - val_loss: 1.2129 - val_categorical_accuracy: 0.5910\n",
      "Epoch 26/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2391 - categorical_accuracy: 0.5971 \n",
      "Epoch 00026: val_loss improved from 1.21289 to 1.20979, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2294 - categorical_accuracy: 0.5997 - val_loss: 1.2098 - val_categorical_accuracy: 0.5910\n",
      "Epoch 27/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2256 - categorical_accuracy: 0.6040 \n",
      "Epoch 00027: val_loss improved from 1.20979 to 1.20294, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2223 - categorical_accuracy: 0.6037 - val_loss: 1.2029 - val_categorical_accuracy: 0.5910\n",
      "Epoch 28/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2343 - categorical_accuracy: 0.5931 \n",
      "Epoch 00028: val_loss improved from 1.20294 to 1.19495, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2262 - categorical_accuracy: 0.5962 - val_loss: 1.1949 - val_categorical_accuracy: 0.5910\n",
      "Epoch 29/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.2045 - categorical_accuracy: 0.6023 \n",
      "Epoch 00029: val_loss improved from 1.19495 to 1.17783, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.2101 - categorical_accuracy: 0.5968 - val_loss: 1.1778 - val_categorical_accuracy: 0.5910\n",
      "Epoch 30/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.1944 - categorical_accuracy: 0.6006 \n",
      "Epoch 00030: val_loss improved from 1.17783 to 1.15557, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.1869 - categorical_accuracy: 0.6045 - val_loss: 1.1556 - val_categorical_accuracy: 0.5910\n",
      "Epoch 31/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.1516 - categorical_accuracy: 0.6020 \n",
      "Epoch 00031: val_loss improved from 1.15557 to 1.13511, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.1591 - categorical_accuracy: 0.6002 - val_loss: 1.1351 - val_categorical_accuracy: 0.5910\n",
      "Epoch 32/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.1237 - categorical_accuracy: 0.6043 \n",
      "Epoch 00032: val_loss improved from 1.13511 to 1.12212, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.1332 - categorical_accuracy: 0.6000 - val_loss: 1.1221 - val_categorical_accuracy: 0.5910\n",
      "Epoch 33/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.1199 - categorical_accuracy: 0.5923 \n",
      "Epoch 00033: val_loss improved from 1.12212 to 1.05783, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.1049 - categorical_accuracy: 0.5990 - val_loss: 1.0578 - val_categorical_accuracy: 0.5910\n",
      "Epoch 34/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 1.0545 - categorical_accuracy: 0.6023 \n",
      "Epoch 00034: val_loss improved from 1.05783 to 1.03654, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 1.0562 - categorical_accuracy: 0.6020 - val_loss: 1.0365 - val_categorical_accuracy: 0.5910\n",
      "Epoch 35/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.0221 - categorical_accuracy: 0.5980 \n",
      "Epoch 00035: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.0344 - categorical_accuracy: 0.6012 - val_loss: 1.2147 - val_categorical_accuracy: 0.5910\n",
      "Epoch 36/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.1110 - categorical_accuracy: 0.6131 \n",
      "Epoch 00036: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.1088 - categorical_accuracy: 0.6132 - val_loss: 1.0715 - val_categorical_accuracy: 0.5910\n",
      "Epoch 37/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 1.0384 - categorical_accuracy: 0.6143 \n",
      "Epoch 00037: val_loss improved from 1.03654 to 0.99514, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 1.0346 - categorical_accuracy: 0.6168 - val_loss: 0.9951 - val_categorical_accuracy: 0.5910\n",
      "Epoch 38/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.9852 - categorical_accuracy: 0.6449 \n",
      "Epoch 00038: val_loss improved from 0.99514 to 0.93243, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.9822 - categorical_accuracy: 0.6458 - val_loss: 0.9324 - val_categorical_accuracy: 0.6220\n",
      "Epoch 39/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.9104 - categorical_accuracy: 0.6914 \n",
      "Epoch 00039: val_loss improved from 0.93243 to 0.88151, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.9129 - categorical_accuracy: 0.6895 - val_loss: 0.8815 - val_categorical_accuracy: 0.7220\n",
      "Epoch 40/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.8625 - categorical_accuracy: 0.7200 \n",
      "Epoch 00040: val_loss improved from 0.88151 to 0.86025, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.8639 - categorical_accuracy: 0.7180 - val_loss: 0.8602 - val_categorical_accuracy: 0.7220\n",
      "Epoch 41/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.8511 - categorical_accuracy: 0.7249 \n",
      "Epoch 00041: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.8561 - categorical_accuracy: 0.7215 - val_loss: 0.8751 - val_categorical_accuracy: 0.7170\n",
      "Epoch 42/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.8466 - categorical_accuracy: 0.7211 \n",
      "Epoch 00042: val_loss improved from 0.86025 to 0.84949, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.8417 - categorical_accuracy: 0.7240 - val_loss: 0.8495 - val_categorical_accuracy: 0.7300\n",
      "Epoch 43/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.8027 - categorical_accuracy: 0.7360 \n",
      "Epoch 00043: val_loss improved from 0.84949 to 0.84118, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.8090 - categorical_accuracy: 0.7317 - val_loss: 0.8412 - val_categorical_accuracy: 0.7280\n",
      "Epoch 44/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7818 - categorical_accuracy: 0.7440 \n",
      "Epoch 00044: val_loss improved from 0.84118 to 0.83462, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7890 - categorical_accuracy: 0.7415 - val_loss: 0.8346 - val_categorical_accuracy: 0.7290\n",
      "Epoch 45/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7761 - categorical_accuracy: 0.7443 \n",
      "Epoch 00045: val_loss improved from 0.83462 to 0.82952, saving model to weights.hdf5\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7791 - categorical_accuracy: 0.7438 - val_loss: 0.8295 - val_categorical_accuracy: 0.7240\n",
      "Epoch 46/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7623 - categorical_accuracy: 0.7400 \n",
      "Epoch 00046: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7624 - categorical_accuracy: 0.7410 - val_loss: 0.8315 - val_categorical_accuracy: 0.7220\n",
      "Epoch 47/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7726 - categorical_accuracy: 0.7400 \n",
      "Epoch 00047: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7687 - categorical_accuracy: 0.7415 - val_loss: 0.8663 - val_categorical_accuracy: 0.7260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7720 - categorical_accuracy: 0.7414 \n",
      "Epoch 00048: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7647 - categorical_accuracy: 0.7440 - val_loss: 0.8617 - val_categorical_accuracy: 0.7260\n",
      "Epoch 49/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7386 - categorical_accuracy: 0.7483 \n",
      "Epoch 00049: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7417 - categorical_accuracy: 0.7460 - val_loss: 0.8467 - val_categorical_accuracy: 0.7250\n",
      "Epoch 50/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7440 - categorical_accuracy: 0.7457 \n",
      "Epoch 00050: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7360 - categorical_accuracy: 0.7480 - val_loss: 0.8450 - val_categorical_accuracy: 0.7230\n",
      "Epoch 51/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7268 - categorical_accuracy: 0.7460 \n",
      "Epoch 00051: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7279 - categorical_accuracy: 0.7472 - val_loss: 0.8449 - val_categorical_accuracy: 0.7220\n",
      "Epoch 52/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 0.7291 - categorical_accuracy: 0.7449 \n",
      "Epoch 00052: val_loss did not improve\n",
      "4000/4000 [==============================] - 70s 17ms/step - loss: 0.7239 - categorical_accuracy: 0.7458 - val_loss: 0.8544 - val_categorical_accuracy: 0.7270\n",
      "Epoch 53/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6966 - categorical_accuracy: 0.7534 \n",
      "Epoch 00053: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.7012 - categorical_accuracy: 0.7530 - val_loss: 0.8927 - val_categorical_accuracy: 0.7220\n",
      "Epoch 54/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6923 - categorical_accuracy: 0.7549 \n",
      "Epoch 00054: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.6893 - categorical_accuracy: 0.7558 - val_loss: 0.8762 - val_categorical_accuracy: 0.7220\n",
      "Epoch 55/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6947 - categorical_accuracy: 0.7526 \n",
      "Epoch 00055: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.6971 - categorical_accuracy: 0.7505 - val_loss: 0.8916 - val_categorical_accuracy: 0.7220\n",
      "Epoch 56/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6860 - categorical_accuracy: 0.7563 \n",
      "Epoch 00056: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.6873 - categorical_accuracy: 0.7533 - val_loss: 0.8814 - val_categorical_accuracy: 0.7250\n",
      "Epoch 57/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6935 - categorical_accuracy: 0.7529 \n",
      "Epoch 00057: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6912 - categorical_accuracy: 0.7545 - val_loss: 0.8760 - val_categorical_accuracy: 0.7120\n",
      "Epoch 58/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6753 - categorical_accuracy: 0.7611 \n",
      "Epoch 00058: val_loss did not improve\n",
      "4000/4000 [==============================] - 65s 16ms/step - loss: 0.6713 - categorical_accuracy: 0.7625 - val_loss: 0.8757 - val_categorical_accuracy: 0.7170\n",
      "Epoch 59/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6741 - categorical_accuracy: 0.7603 \n",
      "Epoch 00059: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6745 - categorical_accuracy: 0.7583 - val_loss: 0.9114 - val_categorical_accuracy: 0.7150\n",
      "Epoch 60/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6675 - categorical_accuracy: 0.7643 \n",
      "Epoch 00060: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6724 - categorical_accuracy: 0.7612 - val_loss: 0.9194 - val_categorical_accuracy: 0.7110\n",
      "Epoch 61/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7050 - categorical_accuracy: 0.7580 \n",
      "Epoch 00061: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.7101 - categorical_accuracy: 0.7585 - val_loss: 1.1047 - val_categorical_accuracy: 0.7090\n",
      "Epoch 62/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.8209 - categorical_accuracy: 0.7477 \n",
      "Epoch 00062: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.8258 - categorical_accuracy: 0.7465 - val_loss: 0.8929 - val_categorical_accuracy: 0.7070\n",
      "Epoch 63/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7638 - categorical_accuracy: 0.7543 \n",
      "Epoch 00063: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.7613 - categorical_accuracy: 0.7525 - val_loss: 0.8947 - val_categorical_accuracy: 0.7180\n",
      "Epoch 64/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7214 - categorical_accuracy: 0.7660 \n",
      "Epoch 00064: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.7238 - categorical_accuracy: 0.7668 - val_loss: 0.8829 - val_categorical_accuracy: 0.7090\n",
      "Epoch 65/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.7259 - categorical_accuracy: 0.7691 \n",
      "Epoch 00065: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.7226 - categorical_accuracy: 0.7710 - val_loss: 0.9097 - val_categorical_accuracy: 0.7210\n",
      "Epoch 66/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6949 - categorical_accuracy: 0.7794 \n",
      "Epoch 00066: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6892 - categorical_accuracy: 0.7810 - val_loss: 0.8928 - val_categorical_accuracy: 0.7220\n",
      "Epoch 67/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6757 - categorical_accuracy: 0.7843 \n",
      "Epoch 00067: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6727 - categorical_accuracy: 0.7862 - val_loss: 0.9275 - val_categorical_accuracy: 0.7270\n",
      "Epoch 68/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6433 - categorical_accuracy: 0.7920 \n",
      "Epoch 00068: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6468 - categorical_accuracy: 0.7907 - val_loss: 0.9322 - val_categorical_accuracy: 0.7200\n",
      "Epoch 69/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6296 - categorical_accuracy: 0.7906 \n",
      "Epoch 00069: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.6360 - categorical_accuracy: 0.7885 - val_loss: 0.9557 - val_categorical_accuracy: 0.7150\n",
      "Epoch 70/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6087 - categorical_accuracy: 0.7949 \n",
      "Epoch 00070: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6191 - categorical_accuracy: 0.7920 - val_loss: 0.9735 - val_categorical_accuracy: 0.7130\n",
      "Epoch 71/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6194 - categorical_accuracy: 0.7963 \n",
      "Epoch 00071: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.6204 - categorical_accuracy: 0.7947 - val_loss: 0.9986 - val_categorical_accuracy: 0.7170\n",
      "Epoch 72/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6353 - categorical_accuracy: 0.7943 \n",
      "Epoch 00072: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6373 - categorical_accuracy: 0.7938 - val_loss: 0.9515 - val_categorical_accuracy: 0.7120\n",
      "Epoch 73/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6144 - categorical_accuracy: 0.8011 \n",
      "Epoch 00073: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6159 - categorical_accuracy: 0.7995 - val_loss: 0.9454 - val_categorical_accuracy: 0.7060\n",
      "Epoch 74/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6045 - categorical_accuracy: 0.8009 \n",
      "Epoch 00074: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.6107 - categorical_accuracy: 0.7985 - val_loss: 0.9663 - val_categorical_accuracy: 0.7070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6170 - categorical_accuracy: 0.7966 \n",
      "Epoch 00075: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.6111 - categorical_accuracy: 0.7988 - val_loss: 0.9648 - val_categorical_accuracy: 0.7230\n",
      "Epoch 76/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5892 - categorical_accuracy: 0.8069 \n",
      "Epoch 00076: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5989 - categorical_accuracy: 0.8055 - val_loss: 1.0358 - val_categorical_accuracy: 0.7190\n",
      "Epoch 77/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5949 - categorical_accuracy: 0.8031 \n",
      "Epoch 00077: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.6075 - categorical_accuracy: 0.8020 - val_loss: 1.0000 - val_categorical_accuracy: 0.7200\n",
      "Epoch 78/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.6056 - categorical_accuracy: 0.8126 \n",
      "Epoch 00078: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.6019 - categorical_accuracy: 0.8147 - val_loss: 0.9725 - val_categorical_accuracy: 0.7190\n",
      "Epoch 79/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5956 - categorical_accuracy: 0.8077 \n",
      "Epoch 00079: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5982 - categorical_accuracy: 0.8070 - val_loss: 0.9909 - val_categorical_accuracy: 0.7160\n",
      "Epoch 80/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5845 - categorical_accuracy: 0.8100 \n",
      "Epoch 00080: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5826 - categorical_accuracy: 0.8108 - val_loss: 0.9960 - val_categorical_accuracy: 0.7160\n",
      "Epoch 81/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5849 - categorical_accuracy: 0.8149 \n",
      "Epoch 00081: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5896 - categorical_accuracy: 0.8133 - val_loss: 0.9957 - val_categorical_accuracy: 0.7180\n",
      "Epoch 82/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5950 - categorical_accuracy: 0.8077 \n",
      "Epoch 00082: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5901 - categorical_accuracy: 0.8067 - val_loss: 0.9787 - val_categorical_accuracy: 0.7210\n",
      "Epoch 83/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5829 - categorical_accuracy: 0.8120 \n",
      "Epoch 00083: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.5832 - categorical_accuracy: 0.8118 - val_loss: 1.0363 - val_categorical_accuracy: 0.7190\n",
      "Epoch 84/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 0.5667 - categorical_accuracy: 0.8166 \n",
      "Epoch 00084: val_loss did not improve\n",
      "4000/4000 [==============================] - 72s 18ms/step - loss: 0.5754 - categorical_accuracy: 0.8155 - val_loss: 1.2086 - val_categorical_accuracy: 0.7130\n",
      "Epoch 85/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5858 - categorical_accuracy: 0.8169 \n",
      "Epoch 00085: val_loss did not improve\n",
      "4000/4000 [==============================] - 68s 17ms/step - loss: 0.5815 - categorical_accuracy: 0.8170 - val_loss: 1.2259 - val_categorical_accuracy: 0.7130\n",
      "Epoch 86/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5576 - categorical_accuracy: 0.8231 \n",
      "Epoch 00086: val_loss did not improve\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.5547 - categorical_accuracy: 0.8233 - val_loss: 1.1738 - val_categorical_accuracy: 0.7170\n",
      "Epoch 87/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5659 - categorical_accuracy: 0.8171 \n",
      "Epoch 00087: val_loss did not improve\n",
      "4000/4000 [==============================] - 68s 17ms/step - loss: 0.5648 - categorical_accuracy: 0.8168 - val_loss: 1.0611 - val_categorical_accuracy: 0.7100\n",
      "Epoch 88/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5829 - categorical_accuracy: 0.8169 \n",
      "Epoch 00088: val_loss did not improve\n",
      "4000/4000 [==============================] - 68s 17ms/step - loss: 0.5870 - categorical_accuracy: 0.8135 - val_loss: 1.0017 - val_categorical_accuracy: 0.7130\n",
      "Epoch 89/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5674 - categorical_accuracy: 0.8200 \n",
      "Epoch 00089: val_loss did not improve\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.5575 - categorical_accuracy: 0.8230 - val_loss: 1.0308 - val_categorical_accuracy: 0.7200\n",
      "Epoch 90/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5648 - categorical_accuracy: 0.8211 \n",
      "Epoch 00090: val_loss did not improve\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.5536 - categorical_accuracy: 0.8255 - val_loss: 1.2482 - val_categorical_accuracy: 0.7110\n",
      "Epoch 91/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 0.5544 - categorical_accuracy: 0.8223 \n",
      "Epoch 00091: val_loss did not improve\n",
      "4000/4000 [==============================] - 81s 20ms/step - loss: 0.5559 - categorical_accuracy: 0.8230 - val_loss: 1.0591 - val_categorical_accuracy: 0.7130\n",
      "Epoch 92/200\n",
      "3500/4000 [=========================>....] - ETA: 14s - loss: 0.5709 - categorical_accuracy: 0.8186\n",
      "Epoch 00092: val_loss did not improve\n",
      "4000/4000 [==============================] - 126s 32ms/step - loss: 0.5674 - categorical_accuracy: 0.8210 - val_loss: 1.0452 - val_categorical_accuracy: 0.7130\n",
      "Epoch 93/200\n",
      "3500/4000 [=========================>....] - ETA: 14s - loss: 0.5601 - categorical_accuracy: 0.8203\n",
      "Epoch 00093: val_loss did not improve\n",
      "4000/4000 [==============================] - 127s 32ms/step - loss: 0.5706 - categorical_accuracy: 0.8185 - val_loss: 1.0419 - val_categorical_accuracy: 0.7080\n",
      "Epoch 94/200\n",
      "3500/4000 [=========================>....] - ETA: 10s - loss: 0.5511 - categorical_accuracy: 0.8254\n",
      "Epoch 00094: val_loss did not improve\n",
      "4000/4000 [==============================] - 82s 21ms/step - loss: 0.5491 - categorical_accuracy: 0.8270 - val_loss: 1.0511 - val_categorical_accuracy: 0.7220\n",
      "Epoch 95/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5532 - categorical_accuracy: 0.8263 \n",
      "Epoch 00095: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5541 - categorical_accuracy: 0.8283 - val_loss: 1.0973 - val_categorical_accuracy: 0.7030\n",
      "Epoch 96/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5379 - categorical_accuracy: 0.8343 \n",
      "Epoch 00096: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5411 - categorical_accuracy: 0.8315 - val_loss: 1.2066 - val_categorical_accuracy: 0.7180\n",
      "Epoch 97/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5342 - categorical_accuracy: 0.8340 \n",
      "Epoch 00097: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5314 - categorical_accuracy: 0.8347 - val_loss: 1.1683 - val_categorical_accuracy: 0.7110\n",
      "Epoch 98/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5399 - categorical_accuracy: 0.8371 \n",
      "Epoch 00098: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5433 - categorical_accuracy: 0.8348 - val_loss: 1.0838 - val_categorical_accuracy: 0.7090\n",
      "Epoch 99/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 0.5419 - categorical_accuracy: 0.8300 \n",
      "Epoch 00099: val_loss did not improve\n",
      "4000/4000 [==============================] - 80s 20ms/step - loss: 0.5392 - categorical_accuracy: 0.8315 - val_loss: 1.1784 - val_categorical_accuracy: 0.7080\n",
      "Epoch 100/200\n",
      "3500/4000 [=========================>....] - ETA: 17s - loss: 0.5334 - categorical_accuracy: 0.8380\n",
      "Epoch 00100: val_loss did not improve\n",
      "4000/4000 [==============================] - 157s 39ms/step - loss: 0.5372 - categorical_accuracy: 0.8375 - val_loss: 1.1293 - val_categorical_accuracy: 0.7080\n",
      "Epoch 101/200\n",
      "3500/4000 [=========================>....] - ETA: 20s - loss: 0.5391 - categorical_accuracy: 0.8326\n",
      "Epoch 00101: val_loss did not improve\n",
      "4000/4000 [==============================] - 172s 43ms/step - loss: 0.5377 - categorical_accuracy: 0.8317 - val_loss: 1.0837 - val_categorical_accuracy: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/200\n",
      "3500/4000 [=========================>....] - ETA: 16s - loss: 0.5313 - categorical_accuracy: 0.8394\n",
      "Epoch 00102: val_loss did not improve\n",
      "4000/4000 [==============================] - 130s 33ms/step - loss: 0.5343 - categorical_accuracy: 0.8385 - val_loss: 1.2133 - val_categorical_accuracy: 0.7170\n",
      "Epoch 103/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5226 - categorical_accuracy: 0.8383 \n",
      "Epoch 00103: val_loss did not improve\n",
      "4000/4000 [==============================] - 69s 17ms/step - loss: 0.5233 - categorical_accuracy: 0.8362 - val_loss: 1.2058 - val_categorical_accuracy: 0.7150\n",
      "Epoch 104/200\n",
      "3500/4000 [=========================>....] - ETA: 8s - loss: 0.5170 - categorical_accuracy: 0.8403 \n",
      "Epoch 00104: val_loss did not improve\n",
      "4000/4000 [==============================] - 72s 18ms/step - loss: 0.5146 - categorical_accuracy: 0.8390 - val_loss: 1.1975 - val_categorical_accuracy: 0.7240\n",
      "Epoch 105/200\n",
      "3500/4000 [=========================>....] - ETA: 10s - loss: 0.5110 - categorical_accuracy: 0.8389\n",
      "Epoch 00105: val_loss did not improve\n",
      "4000/4000 [==============================] - 89s 22ms/step - loss: 0.5222 - categorical_accuracy: 0.8357 - val_loss: 1.1817 - val_categorical_accuracy: 0.7140\n",
      "Epoch 106/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5193 - categorical_accuracy: 0.8371 \n",
      "Epoch 00106: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.5224 - categorical_accuracy: 0.8352 - val_loss: 1.1930 - val_categorical_accuracy: 0.7170\n",
      "Epoch 107/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5218 - categorical_accuracy: 0.8403 \n",
      "Epoch 00107: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5293 - categorical_accuracy: 0.8398 - val_loss: 1.1993 - val_categorical_accuracy: 0.7220\n",
      "Epoch 108/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5268 - categorical_accuracy: 0.8326 \n",
      "Epoch 00108: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5190 - categorical_accuracy: 0.8362 - val_loss: 1.1708 - val_categorical_accuracy: 0.7150\n",
      "Epoch 109/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5214 - categorical_accuracy: 0.8331 \n",
      "Epoch 00109: val_loss did not improve\n",
      "4000/4000 [==============================] - 67s 17ms/step - loss: 0.5121 - categorical_accuracy: 0.8353 - val_loss: 1.2337 - val_categorical_accuracy: 0.7150\n",
      "Epoch 110/200\n",
      "3500/4000 [=========================>....] - ETA: 11s - loss: 0.5019 - categorical_accuracy: 0.8414\n",
      "Epoch 00110: val_loss did not improve\n",
      "4000/4000 [==============================] - 112s 28ms/step - loss: 0.5087 - categorical_accuracy: 0.8397 - val_loss: 1.2215 - val_categorical_accuracy: 0.7220\n",
      "Epoch 111/200\n",
      "3500/4000 [=========================>....] - ETA: 20s - loss: 0.5055 - categorical_accuracy: 0.8349\n",
      "Epoch 00111: val_loss did not improve\n",
      "4000/4000 [==============================] - 172s 43ms/step - loss: 0.5105 - categorical_accuracy: 0.8347 - val_loss: 1.1778 - val_categorical_accuracy: 0.7200\n",
      "Epoch 112/200\n",
      "3500/4000 [=========================>....] - ETA: 19s - loss: 0.5031 - categorical_accuracy: 0.8377\n",
      "Epoch 00112: val_loss did not improve\n",
      "4000/4000 [==============================] - 181s 45ms/step - loss: 0.5189 - categorical_accuracy: 0.8323 - val_loss: 1.1532 - val_categorical_accuracy: 0.7170\n",
      "Epoch 113/200\n",
      "3500/4000 [=========================>....] - ETA: 12s - loss: 0.5163 - categorical_accuracy: 0.8363\n",
      "Epoch 00113: val_loss did not improve\n",
      "4000/4000 [==============================] - 107s 27ms/step - loss: 0.5199 - categorical_accuracy: 0.8330 - val_loss: 1.1174 - val_categorical_accuracy: 0.7190\n",
      "Epoch 114/200\n",
      "3500/4000 [=========================>....] - ETA: 9s - loss: 0.5126 - categorical_accuracy: 0.8374 \n",
      "Epoch 00114: val_loss did not improve\n",
      "4000/4000 [==============================] - 80s 20ms/step - loss: 0.5172 - categorical_accuracy: 0.8360 - val_loss: 1.1855 - val_categorical_accuracy: 0.7210\n",
      "Epoch 115/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5098 - categorical_accuracy: 0.8314 \n",
      "Epoch 00115: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.5174 - categorical_accuracy: 0.8302 - val_loss: 1.1844 - val_categorical_accuracy: 0.7260\n",
      "Epoch 116/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5122 - categorical_accuracy: 0.8380 \n",
      "Epoch 00116: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.5173 - categorical_accuracy: 0.8342 - val_loss: 1.1341 - val_categorical_accuracy: 0.7320\n",
      "Epoch 117/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5131 - categorical_accuracy: 0.8403 \n",
      "Epoch 00117: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.5071 - categorical_accuracy: 0.8425 - val_loss: 1.1194 - val_categorical_accuracy: 0.7190\n",
      "Epoch 118/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5002 - categorical_accuracy: 0.8411 \n",
      "Epoch 00118: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 16ms/step - loss: 0.4919 - categorical_accuracy: 0.8433 - val_loss: 1.1377 - val_categorical_accuracy: 0.7170\n",
      "Epoch 119/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.5103 - categorical_accuracy: 0.8374 \n",
      "Epoch 00119: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.4990 - categorical_accuracy: 0.8415 - val_loss: 1.1223 - val_categorical_accuracy: 0.7210\n",
      "Epoch 120/200\n",
      "3500/4000 [=========================>....] - ETA: 7s - loss: 0.4973 - categorical_accuracy: 0.8389 \n",
      "Epoch 00120: val_loss did not improve\n",
      "4000/4000 [==============================] - 66s 17ms/step - loss: 0.4959 - categorical_accuracy: 0.8405 - val_loss: 1.1306 - val_categorical_accuracy: 0.7230\n",
      "Epoch 121/200\n",
      "2000/4000 [==============>...............] - ETA: 30s - loss: 0.5020 - categorical_accuracy: 0.8360"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='weights.hdf5', verbose=1, save_best_only=True)\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=500,\n",
    "          validation_data = [X_test,y_test],\n",
    "          callbacks=[checkpointer],class_weight = class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(y_train,y_test,y_train_pred,y_test_pred):\n",
    "    \n",
    "    class_names = ['unknown',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    \n",
    "    class_names_b = ['neg', 'pos']\n",
    "    print('train scores\\n')\n",
    "    print(classification_report(y_train, y_train_pred, target_names = class_names))\n",
    "    print('test scores\\n')\n",
    "    print(classification_report(y_test, y_test_pred, target_names = class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "           Other       0.80      0.80      0.80        10\n",
      "           Crash       0.33      0.20      0.25        10\n",
      "Balance problems       0.00      0.00      0.00        10\n",
      " Synchronization       0.29      0.80      0.42        10\n",
      "        Positive       0.60      0.60      0.60        10\n",
      "             Bug       0.00      0.00      0.00        10\n",
      "\n",
      "     avg / total       0.34      0.40      0.35        60\n",
      "\n",
      "model accuracy 0.4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dns/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,roc_auc_score,accuracy_score, classification_report\n",
    "def eval_network(input_text, model = model):\n",
    "    cleaned_text = clean_comment(input_text)\n",
    "    class_names = ['Other',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']\n",
    "    seq = t.texts_to_sequences([cleaned_text])\n",
    "    padded_sequence = sequence.pad_sequences(seq, maxlen=max_length)\n",
    "    prediction = model.predict(padded_sequence)\n",
    "    #print(class_names[prediction[0]])\n",
    "    return np.argmax(class_weight*prediction[0])\n",
    "\n",
    "def val_score(model):\n",
    "    class_names = ['Other',\n",
    "        'Crash',\n",
    "        'Balance problems',\n",
    "        'Synchronization',\n",
    "        'Positive',\n",
    "        'Bug']    \n",
    "    val_en = pd.read_excel('validation_en.xlsx')\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for i in range(0,6):\n",
    "        y_true.append([i]*10)\n",
    "        y_pred.append(val_en.iloc[:,i].apply(eval_network))\n",
    "    y_true = np.array(y_true).flatten()\n",
    "    y_pred = np.array(y_pred).flatten()\n",
    "    print(classification_report(y_true, y_pred, target_names = class_names))\n",
    "    print('model accuracy %1.4f'%(accuracy_score(y_true, y_pred)))\n",
    "    return y_true,y_pred\n",
    "y_true,y_pred = val_score(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('this dum gaem crashes every time i launch it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('those new weapons are so dam op')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('The game glitched and all of my trophies and guns are now lost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('Cool!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('This game is haard to control')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_network('Mucho gusto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
